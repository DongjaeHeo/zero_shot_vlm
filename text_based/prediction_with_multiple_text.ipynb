{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d928d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T07:02:24.209253Z",
     "start_time": "2025-07-13T07:00:04.694660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dromii4/dromii/owlv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Processing DJI_0951.JPG …\n",
      "  [OK] Saved → DJI_0951.JPG, DJI_0951.json\n",
      "\n",
      "▶ Processing DJI_0691.JPG …\n",
      "  [OK] Saved → DJI_0691.JPG, DJI_0691.json\n",
      "\n",
      "▶ Processing DJI_0033.JPG …\n",
      "  [OK] Saved → DJI_0033.JPG, DJI_0033.json\n",
      "\n",
      "▶ Processing DJI_0559.jpg …\n",
      "  [OK] Saved → DJI_0559.jpg, DJI_0559.json\n",
      "\n",
      "▶ Processing DJI_0934.jpg …\n",
      "  [OK] Saved → DJI_0934.jpg, DJI_0934.json\n",
      "\n",
      "▶ Processing DJI_0923.jpg …\n",
      "  [OK] Saved → DJI_0923.jpg, DJI_0923.json\n",
      "\n",
      "▶ Processing DJI_0008.JPG …\n",
      "  [OK] Saved → DJI_0008.JPG, DJI_0008.json\n",
      "\n",
      "▶ Processing DJI_0933.jpg …\n",
      "  [OK] Saved → DJI_0933.jpg, DJI_0933.json\n",
      "\n",
      "▶ Processing DJI_0866.JPG …\n",
      "  [OK] Saved → DJI_0866.JPG, DJI_0866.json\n",
      "\n",
      "▶ Processing DJI_0036.JPG …\n",
      "  [OK] Saved → DJI_0036.JPG, DJI_0036.json\n",
      "\n",
      "▶ Processing DJI_0928.jpg …\n",
      "  [OK] Saved → DJI_0928.jpg, DJI_0928.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "다중 텍스트 프롬프트 기반 객체 탐지 예제\n",
    "===============================================\n",
    "이 노트북은 각 클래스별로 여러 개의 텍스트 프롬프트를 사용한 객체 탐지 예제입니다.\n",
    "다양한 프롬프트를 통해 탐지 성능을 높이려 했으나, 실제로는 프롬프트 품질에 따른 \n",
    "성능 편차가 크다는 한계가 발견되어 임베딩 기반 솔루션으로 전환되었습니다.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from transformers import Owlv2Processor, Owlv2ForObjectDetection\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ==================== 디렉토리 설정 ====================\n",
    "IMAGE_DIR   = Path(\"encumbrance_labels/encumbrance\")           # 원본 이미지 디렉토리\n",
    "OUTPUT_DIR  = Path(\"encumbrance_labels/prediction_with_multiple_text\")  # 결과 저장 디렉토리\n",
    "\n",
    "# ==================== 하이퍼파라미터 ====================\n",
    "TARGET_SIZE    = 1008    # OWLv2 최적 입력 크기 (14×72 패치)\n",
    "TEXT_THRESHOLD = 0.3     # 텍스트-이미지 매칭 신뢰도 임계값\n",
    "IOU_THRESHOLD  = 0.5     # NMS IoU 임계값\n",
    "\n",
    "# ==================== 디바이스 설정 ====================\n",
    "# Apple Silicon (MPS) > NVIDIA GPU (CUDA) > CPU 순서로 선택\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")  # Apple Silicon GPU\n",
    "else:\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # NVIDIA GPU 또는 CPU\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ==================== 프롬프트 전략 ====================\n",
    "# 클래스별 다양한 영어 프롬프트 5개씩 정의\n",
    "# 각 클래스마다 서로 다른 표현을 사용하여 탐지 성능 향상 시도\n",
    "QUERY_PROMPTS = {\n",
    "    \"Tomb\": [  # 무덤/고분 클래스\n",
    "        \"Korean burial mound\",\n",
    "        \"ancient tomb site\",\n",
    "        \"grave mound\",\n",
    "        \"traditional burial mound\",\n",
    "        \"burial site covered with grass\"\n",
    "    ],\n",
    "    \"Tree\": [\n",
    "        \"isolated tree canopy\",\n",
    "        \"deciduous tree\",\n",
    "        \"single tall tree\",\n",
    "        \"green leafed tree\",\n",
    "        \"mature oak tree\"\n",
    "    ],\n",
    "    \"Greenhouse\": [\n",
    "        \"plastic greenhouse\",\n",
    "        \"glass greenhouse structure\",\n",
    "        \"hoop house greenhouse\",\n",
    "        \"abandoned greenhouse frame\",\n",
    "        \"greenhouse with plastic cover\"\n",
    "    ],\n",
    "    \"Building\": [\n",
    "        \"single story building\",\n",
    "        \"flat roof house\",\n",
    "        \"residential building structure\",\n",
    "        \"industrial shed building\",\n",
    "        \"roofed concrete building\"\n",
    "    ],\n",
    "    \"Field\": [\n",
    "        \"agricultural field\",\n",
    "        \"plowed farmland\",\n",
    "        \"cultivated crop field\",\n",
    "        \"rice paddy field\",\n",
    "        \"open grass field\"\n",
    "    ],\n",
    "    \"Container\": [\n",
    "        \"shipping container\",\n",
    "        \"cargo container\",\n",
    "        \"metal storage container\",\n",
    "        \"freight container box\",\n",
    "        \"stacked container unit\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 클래스별 시각화 색상 (RGB)\n",
    "COLOR_MAP = {\n",
    "    \"Tomb\":       (  0,   0, 255),\n",
    "    \"Tree\":       (  0, 255,   0),\n",
    "    \"Greenhouse\": (255,   0,   0),\n",
    "    \"Building\":   (  0, 255, 255),\n",
    "    \"Field\":      (255,   0, 255),\n",
    "    \"Container\":  (255, 255,   0),\n",
    "}\n",
    "# ────────────────────────────────────────────────────────────\n",
    "\n",
    "# ==================== 모델 초기화 ====================\n",
    "# 1) OWLv2 모델 & 프로세서 로드 \n",
    "processor = Owlv2Processor.from_pretrained(\n",
    "    \"google/owlv2-large-patch14-ensemble\",\n",
    "    image_size=TARGET_SIZE  # 1008x1008 입력 크기\n",
    ")\n",
    "model = Owlv2ForObjectDetection.from_pretrained(\n",
    "    \"google/owlv2-large-patch14-ensemble\"\n",
    ").to(DEVICE).eval()  # 평가 모드로 설정\n",
    "\n",
    "# 2) 출력 폴더 준비\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "font = ImageFont.load_default()  # 텍스트 표시용 폰트\n",
    "\n",
    "# ==================== 메인 처리 루프 ====================\n",
    "# 3) 이미지별 처리 - 각 이미지에 대해 다중 프롬프트 탐지 수행\n",
    "for img_path in IMAGE_DIR.glob(\"*\"):\n",
    "    # 지원하는 이미지 형식만 처리\n",
    "    if img_path.suffix.lower() not in {\".jpg\", \".jpeg\", \".png\"}:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n▶ Processing {img_path.name} …\")\n",
    "    \n",
    "    # ==================== 이미지 전처리 ====================\n",
    "    # 원본 이미지 로드 및 RGB 변환\n",
    "    orig = Image.open(img_path).convert(\"RGB\")\n",
    "    # OWLv2 모델 입력 크기로 리사이징\n",
    "    img  = orig.resize((TARGET_SIZE, TARGET_SIZE), Image.BILINEAR)\n",
    "    w, h = img.size  # w == h == 1008\n",
    "\n",
    "    # ==================== 다중 프롬프트 탐지 결과 저장용 리스트 ====================\n",
    "    all_boxes, all_scores, all_labels = [], [], []\n",
    "\n",
    "    # ==================== 4단계: 클래스별 다중 텍스트 프롬프트 탐지 ====================\n",
    "    # 각 클래스마다 5개의 서로 다른 프롬프트로 탐지 수행\n",
    "    for cls, prompts in QUERY_PROMPTS.items():\n",
    "        print(f\"  클래스 '{cls}' 탐지 중... ({len(prompts)}개 프롬프트)\")\n",
    "        \n",
    "        # ==================== OWLv2 모델 입력 준비 ====================\n",
    "        # 다중 프롬프트와 단일 이미지를 프로세서에 전달\n",
    "        inputs = processor(\n",
    "            text=prompts,      # 5개의 서로 다른 프롬프트\n",
    "            images=img,        # 동일한 이미지\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # GPU로 데이터 이동 (가능한 경우)\n",
    "        for k, v in inputs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(DEVICE)\n",
    "\n",
    "        # ==================== 모델 추론 및 후처리 ====================\n",
    "        # GPU 메모리 사용량 최적화를 위한 no_grad 컨텍스트\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)  # OWLv2 모델 추론\n",
    "            \n",
    "        # 모델 출력을 바운딩 박스, 점수, 라벨로 변환\n",
    "        results = processor.post_process_object_detection(\n",
    "            outputs=outputs,\n",
    "            target_sizes=torch.tensor([[h, w]], device=DEVICE),  # 원본 이미지 크기\n",
    "            threshold=TEXT_THRESHOLD  # 신뢰도 임계값 적용\n",
    "        )\n",
    "\n",
    "        # ==================== 결과 수집 ====================\n",
    "        # 각 프롬프트별 탐지 결과를 전체 리스트에 추가\n",
    "        for res in results:\n",
    "            for box, score in zip(res[\"boxes\"], res[\"scores\"]):\n",
    "                all_boxes.append(box)      # 바운딩 박스 좌표\n",
    "                all_scores.append(score)   # 신뢰도 점수\n",
    "                all_labels.append(cls)     # 클래스명\n",
    "\n",
    "    # ==================== 5단계: 전역 Non-Maximum Suppression (NMS) ====================\n",
    "    # 모든 클래스의 탐지 결과를 통합하여 중복 제거\n",
    "    if not all_boxes:\n",
    "        print(f\"  [WARN] No detections for {img_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # 텐서로 변환\n",
    "    boxes_t  = torch.stack(all_boxes)   # 모든 바운딩 박스를 하나의 텐서로\n",
    "    scores_t = torch.stack(all_scores)  # 모든 점수를 하나의 텐서로\n",
    "    \n",
    "    # NMS 적용: 겹치는 박스들 중에서 가장 높은 점수의 박스만 유지\n",
    "    keep     = nms(boxes_t, scores_t, IOU_THRESHOLD)\n",
    "\n",
    "    # ==================== 6단계: 시각화 및 JSON 작성 ====================\n",
    "    draw = ImageDraw.Draw(img)  # 이미지에 그리기 객체 생성\n",
    "    records = []  # JSON 저장용 결과 리스트\n",
    "\n",
    "    # NMS로 필터링된 최종 탐지 결과에 대해 시각화\n",
    "    for i in keep:\n",
    "        # ==================== 박스 좌표 처리 ====================\n",
    "        x1, y1, x2, y2 = boxes_t[i].tolist()\n",
    "        # 이미지 경계를 벗어나는 박스 좌표를 이미지 내부로 제한\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        # 클래스 정보 및 색상 설정\n",
    "        label = all_labels[i]  # 클래스명\n",
    "        score = float(scores_t[i])  # 신뢰도 점수\n",
    "        color = COLOR_MAP.get(label, (255,255,255))  # 클래스별 색상\n",
    "\n",
    "        # ==================== 바운딩 박스 그리기 ====================\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
    "        \n",
    "        # ==================== 라벨 텍스트 표시 ====================\n",
    "        txt = f\"{label}: {score:.2f}\"  # 클래스명과 신뢰도 점수\n",
    "        # 텍스트 배경 박스 계산\n",
    "        tx0, ty0, tx1, ty1 = draw.textbbox((x1, y1), txt, font=font)\n",
    "        # 텍스트 배경 그리기\n",
    "        draw.rectangle([tx0, ty0, tx1, ty1], fill=color)\n",
    "        # 흰색 텍스트 그리기\n",
    "        draw.text((x1, y1), txt, fill=(255,255,255), font=font)\n",
    "\n",
    "        # ==================== JSON 기록용 데이터 추가 ====================\n",
    "        records.append({\n",
    "            \"label\": label,\n",
    "            \"score\": score,\n",
    "            \"box\": [round(x1,2), round(y1,2), round(x2,2), round(y2,2)]\n",
    "        })\n",
    "\n",
    "    # ==================== 7단계: 결과 파일 저장 ====================\n",
    "    out_img  = OUTPUT_DIR / img_path.name  # 시각화된 이미지 저장 경로\n",
    "    out_json = OUTPUT_DIR / f\"{img_path.stem}.json\"  # JSON 결과 저장 경로\n",
    "    \n",
    "    # 시각화된 이미지 저장\n",
    "    img.save(out_img)\n",
    "    # JSON 결과 저장 (UTF-8 인코딩, 한글 지원)\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dump(records, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"  [OK] Saved → {out_img.name}, {out_json.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74914f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233818fdae701fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owlv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
